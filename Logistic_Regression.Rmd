---
title: "Logistic Regression & Regularization"
output: pdf_document
date: "2024-11-20"
---
## Standardize Data 
```{r}
library(tidymodels)
library(tidyverse)
library(ggplot2)
library(knitr)

set.seed(445)

data <- read.csv("heart_failure_clinical_records_dataset.csv")

# scale continuous variables
numeric_vars <- sapply(data, is.numeric)
boolean_vars <- sapply(data, function(x) all(x %in% c(0,1)))

need_scale <- numeric_vars & !boolean_vars

data[need_scale] <- scale(data[need_scale])
```

## Logistic Regression with No Regularization
```{r}
# convert DEATH_EVENT to a factor 
data <- data %>%
  mutate(DEATH_EVENT = factor(DEATH_EVENT, levels = c("0", "1")))

# split data into training set (80%) and test set (20%)
data_split <- initial_split(data, prop = 0.8)
train_data <- training(data_split)
test_data <- testing(data_split)

prep_data <- recipe(DEATH_EVENT ~ ., data = train_data)

# fit logistic regression model
logistic_spec <- logistic_reg(penalty = 0) %>%
  set_mode("classification") %>%
  set_engine("glmnet")

final_logistic_workflow <- workflow() %>%
  add_model(logistic_spec) %>%
  add_recipe(prep_data)

final_logistic_model <- fit(final_logistic_workflow, data = train_data)

# evaluate logistic model on test set
logistic_predictions <- predict(final_logistic_model, test_data, type = "prob") %>%
  bind_cols(test_data) %>%
  # creating pred_class column by converting probabilities into class predictions
  mutate(.pred_class = factor(if_else(.pred_1 >= 0.5, 1, 0), levels = levels(DEATH_EVENT)))

logistic_metrics <- roc_auc(logistic_predictions, truth = DEATH_EVENT, .pred_1) %>%
  bind_rows(accuracy(logistic_predictions, truth = DEATH_EVENT, .pred_class))

# print logistic model metrics
print(logistic_metrics)
```

The logistic regression model with no regularization has a roc_auc of 0.133 and an accuracy of 0.833. 

```{r}
library(tidymodels)
library(kableExtra)

# Fit logistic regression model with stats::glm
logistic_spec_glm <- logistic_reg(penalty = NULL) %>%
  set_mode("classification") %>%
  set_engine("glm")

final_logistic_workflow_glm <- workflow() %>%
  add_model(logistic_spec_glm) %>%
  add_recipe(prep_data)

final_logistic_model_glm <- fit(final_logistic_workflow_glm, data = train_data)

# Extract p-values from model
logistic_glm_fit <- final_logistic_model_glm %>% 
  extract_fit_engine() %>% 
  summary()

# Create a dataframe of coefficients and p-values
p_values_df <- data.frame(
  Estimate = logistic_glm_fit$coefficients[, "Estimate"],
  `Std. Error` = logistic_glm_fit$coefficients[, "Std. Error"],
  `p value` = logistic_glm_fit$coefficients[, "Pr(>|z|)"]
)

# Display p-values
p_values_df %>%
  kbl(caption = "Logistic Regression Coefficients and P-values", digits = 3) %>%
  kable_styling(full_width = F, bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>%
  row_spec(0, bold = T) %>%
  scroll_box(height = "400px")
```

```{r}
# display odds ratios, confidence intervals for odds ratios, and p-values
# didn't end up using this

logistic_glm <- glm(DEATH_EVENT ~ ., data = train_data, family = binomial)

coef_summary <- summary(logistic_glm)$coefficients
p_values <- coef_summary[, 4]

odds_ratios <- exp(coef(logistic_glm))
conf_int <- exp(confint(logistic_glm))

results_df <- data.frame(
  Odds_Ratio = odds_ratios,
  Lower_CI = conf_int[, 1],
  Upper_CI = conf_int[, 2],
  P_Value = p_values)

results_df %>%
  arrange(P_Value) %>%
  knitr::kable(
    caption = "Logistic Regression Results",
    digits = 3,
    align = "c")
```


## Ridge Regression
```{r}
library(tidymodels)
library(tidyverse)
library(ggplot2)

# create vector of 100 lambda values from 0.01 to 10^10
lambda <- lambda <- 10^seq(-2, 10, length.out = 100)
tune_df <- data.frame(lambda = lambda)

# fit ridge regression model for each lambda
prep_data <- recipe(DEATH_EVENT ~ ., data = data)

ridge_ests <- data.frame()

for(lam in lambda) {
  ridge_spec <- logistic_reg(mixture = 0, penalty = lam) |>
    set_mode("classification") |>
    set_engine("glmnet")
  
    workflow() |>
    add_model(ridge_spec) |>
    add_recipe(prep_data) |>
    fit(data) |>
    tidy() |>
    bind_rows(ridge_ests) -> ridge_ests
}

# visualize estimated coefficients for each lambda
ridge_ests |>
  filter(term != "(Intercept)") |>
  ggplot() +
  geom_line(aes(penalty, estimate, group = term, colour = term)) +
  coord_trans(x = "log10")

# perform 10-fold cross validation, estimate roc_auc for each lambda
data_10foldcv <- vfold_cv(data, v = 10)

ridge_spec <- logistic_reg(mixture = 0, penalty = tune("lambda")) |>
  set_mode("classification") |>
  set_engine("glmnet")

workflow() |>
  add_model(ridge_spec) |>
  add_recipe(prep_data) |>
  tune_grid(resamples = data_10foldcv, grid = tune_df, metrics = metric_set(roc_auc, accuracy)) -> ridge_tune

ridge_tune |>
  collect_metrics() |>
  select(lambda, .metric, mean) |>
  pivot_wider(names_from = .metric, values_from = mean) |>
  ggplot() +
  geom_line(aes(lambda, roc_auc)) + 
  geom_point(aes(lambda, roc_auc)) +
  coord_trans(x = "log10")

# determine best lambda
show_best(ridge_tune, metric = "roc_auc", n = 1)
```


## Lasso
```{r}

# fit lasso model for each lambda
lasso_ests <- data.frame()
for(lam in lambda) {
  lasso_spec <- logistic_reg(mixture = 1, penalty = lam) |>
    set_mode("classification") |>
    set_engine("glmnet")
  
    workflow() |>
    add_model(lasso_spec) |>
    add_recipe(prep_data) |>
    fit(data) |>
    tidy() |>
    bind_rows(lasso_ests) -> lasso_ests
}

# visualize estimated coefficients for each lambda
lasso_ests |>
  filter(term != "(Intercept)") |>
  ggplot() +
  geom_line(aes(penalty, estimate, group = term, colour = term)) +
  coord_trans(x = "log10")

# perform 10-fold cross validation, estimate roc_auc for each lambda
lasso_spec <- logistic_reg(mixture = 1, penalty = tune("lambda")) |>
  set_mode("classification") |>
  set_engine("glmnet")

workflow() |>
  add_model(lasso_spec) |>
  add_recipe(prep_data) |>
  tune_grid(resamples = data_10foldcv, grid = tune_df, metrics = metric_set(roc_auc, accuracy)) -> lasso_tune

lasso_tune |>
  collect_metrics() |>
  select(lambda, .metric, mean) |>
  pivot_wider(names_from = .metric, values_from = mean) |>
  ggplot() +
  geom_line(aes(lambda, roc_auc)) +
  geom_point(aes(lambda, roc_auc)) +
  coord_trans(x = "log10")

show_best(lasso_tune, metric = "roc_auc", n = 1)
```

```{r}
ridge_metrics <- ridge_tune |>
  collect_metrics() |>
  filter(.metric == "roc_auc") |>
  mutate(method = "Ridge")

lasso_metrics <- lasso_tune |>
  collect_metrics() |>
  filter(.metric == "roc_auc") |>
  mutate(method = "Lasso")

combined_metrics <- bind_rows(ridge_metrics, lasso_metrics)

combined_metrics |>
  ggplot(aes(x = lambda, y = mean, color = method)) +
  geom_line() +
  geom_point() +
  coord_trans(x = "log10") +
  labs(
    title = "Comparison of Ridge and Lasso Regression",
    x = "Lambda (Log Scale)",
    y = "roc_auc",
    color = "Method")

ridge_best <- show_best(ridge_tune, metric = "roc_auc", n = 1)
print(ridge_best)

lasso_best <- show_best(lasso_tune, metric = "roc_auc", n = 1)
print(lasso_best)
```

```{r, warning=FALSE}
# show best lambda with ridge regression
ridge_tune |>
  collect_metrics() |>
  select(lambda, .metric, mean) |>
  pivot_wider(names_from = .metric, values_from = mean) |>
  ggplot() +
  geom_line(aes(lambda, roc_auc)) + 
  geom_point(aes(lambda, roc_auc)) +
  geom_point(aes(ridge_best$lambda, ridge_best$mean), color = "red") +
  coord_trans(x = "log10")

# show best lmabda with lasso
lasso_tune |>
  collect_metrics() |>
  select(lambda, .metric, mean) |>
  pivot_wider(names_from = .metric, values_from = mean) |>
  ggplot() +
  geom_line(aes(lambda, roc_auc)) +
  geom_point(aes(lambda, roc_auc)) +
  geom_point(aes(lasso_best$lambda, lasso_best$mean), color = "red") +
  coord_trans(x = "log10")
```


## Fit Logistic Models
```{r}
# finalize ridge with best lambda
best_ridge_lambda <- show_best(ridge_tune, metric = "roc_auc", n = 1)$lambda

final_ridge_spec <- logistic_reg(penalty = best_ridge_lambda, mixture = 0) %>%
  set_mode("classification") %>%
  set_engine("glmnet")

final_ridge_workflow <- workflow() %>%
  add_model(final_ridge_spec) %>%
  add_recipe(prep_data)

final_ridge_model <- fit(final_ridge_workflow, data = train_data)

# finalize lasso with best lambda
best_lasso_lambda <- show_best(lasso_tune, metric = "roc_auc", n = 1)$lambda

final_lasso_spec <- logistic_reg(penalty = best_lasso_lambda, mixture = 1) %>%
  set_mode("classification") %>%
  set_engine("glmnet")

final_lasso_workflow <- workflow() %>%
  add_model(final_lasso_spec) %>%
  add_recipe(prep_data)

final_lasso_model <- fit(final_lasso_workflow, data = train_data)
```

## Evaluate Performance
```{r}
# evaluate ridge model on test set
ridge_predictions <- predict(final_ridge_model, test_data, type = "prob") %>%
  bind_cols(test_data) %>%
  # creating pred_class column by converting probabilities into class predictions
  mutate(.pred_class = factor(if_else(.pred_1 >= 0.5, 1, 0), levels = levels(DEATH_EVENT)))

ridge_metrics <- roc_auc(ridge_predictions, truth = DEATH_EVENT, .pred_1) %>%
  bind_rows(accuracy(ridge_predictions, truth = DEATH_EVENT, .pred_class))

# evaluate lasso model on test set
lasso_predictions <- predict(final_lasso_model, test_data, type = "prob") %>%
  bind_cols(test_data) %>%
  # creating pred_class column by converting probabilities into class predictions
  mutate(.pred_class = factor(if_else(.pred_1 >= 0.5, 1, 0), levels = levels(DEATH_EVENT)))

lasso_metrics <- roc_auc(lasso_predictions, truth = DEATH_EVENT, .pred_1) %>%
  bind_rows(accuracy(lasso_predictions, truth = DEATH_EVENT, .pred_class))

# print ridge model metrics
print(ridge_metrics)

# print lasso model metrics
print(lasso_metrics)
```
Ridge regression model has a higher roc_auc of 0.137, but a lower accuracy of 0.833 compared to the Lasso model with a roc_auc of 0.103 and accuracy of 0.850. All of these values are very similar to that of the logistic model with no regularization.

```{r}
# Ridge Regression Estimates

# fit ridge regression model 
ridge_spec_glm <- logistic_reg(penalty = best_ridge_lambda, mixture = 0) %>%
  set_mode("classification") %>%
  set_engine("glm")

final_ridge_workflow_glm <- workflow() %>%
  add_model(ridge_spec_glm) %>%
  add_recipe(prep_data)

final_ridge_model_glm <- fit(final_ridge_workflow_glm, data = train_data)

# extract p-values from model
ridge_glm_fit <- final_ridge_model_glm %>% 
  extract_fit_engine() %>% 
  summary()

# create a dataframe of coefficients and p-values
p_values_df <- data.frame(
  Estimate = ridge_glm_fit$coefficients[, "Estimate"],
  `Std. Error` = ridge_glm_fit$coefficients[, "Std. Error"],
  `p value` = ridge_glm_fit$coefficients[, "Pr(>|z|)"]
)

# display p-values
p_values_df %>%
  kbl(digits = 3) %>%
  kable_styling(full_width = F, bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>%
  row_spec(0, bold = T) %>%
  scroll_box(height = "300px")
```

```{r}
# Lasso Estimates

# fit lasso model 
lasso_spec_glm <- logistic_reg(penalty = best_lasso_lambda, mixture = 0) %>%
  set_mode("classification") %>%
  set_engine("glm")

final_lasso_workflow_glm <- workflow() %>%
  add_model(lasso_spec_glm) %>%
  add_recipe(prep_data)

final_lasso_model_glm <- fit(final_lasso_workflow_glm, data = train_data)

# extract p-values from model
lasso_glm_fit <- final_lasso_model_glm %>% 
  extract_fit_engine() %>% 
  summary()

# create a dataframe of coefficients and p-values
p_values_df <- data.frame(
  Estimate = lasso_glm_fit$coefficients[, "Estimate"],
  `Std. Error` = lasso_glm_fit$coefficients[, "Std. Error"],
  `p value` = lasso_glm_fit$coefficients[, "Pr(>|z|)"]
)

# display p-values
p_values_df %>%
  kbl(digits = 3) %>%
  kable_styling(full_width = F, bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>%
  row_spec(0, bold = T) %>%
  scroll_box(height = "300px")
```

