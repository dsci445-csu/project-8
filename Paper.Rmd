---
title: "DSCI 445 Project Paper"
author: "Paige Galvan, Neha Deshpande, & Witlie Leslie"
date: "2024-11-25"
output: pdf_document
---

# Motivation

The goal of our project is to predict mortality from heart failure using behavioral risk factor data. Heart 
faliture is a disease that affects millions of people yearly. Although modern medicine has improved it can 
be hard to determine causes of heart failure due to how many variables can affect it. The Heart Failure 
Clinical Records Dataset provides a collection of medical indicators such as age, ejection 
fraction, serum creatinine, and co-existing conditions like diabetes and high blood pressure. By analyzing this
data, researchers can uncover patterns that contribute to better understanding the progression of heart
failure.

The main motivation for our group to study this dataset is to dive a little bit deeper on which factors affect 
heart failure. Knowing that heart failure is a leading cause of death around the world, finding meaningful 
patterns can inform public health strategies, such as targeted lifestyle modifications or health care 
campaigns. The main objective is to transform this raw data into meaningful conclusions on heart disease. 

# Methodology

#### Exploratory Analysis 

Before applying machine learning models, we began by performing an exploratory analysis of the data. This 
included assessing the linearity and normality of the predictors, identifying any outliers, and exploring 
potential correlations among the variables. We visualized distributions using histograms and box plots to 
understand the spread of each feature, and scatter plots to check the relationships between the predictor 
variables and the target variable (mortality). This helped us determine whether the data required 
transformations before applying machine learning techniques.



#### Logistic Regression with Regularization


Logistic regression is a go-to method for binary classification, and we explored three versions to analyze 
predictive performance. First, we fit a basic logistic regression model without regularization as a baseline. 
While simple, it doesn't handle collinearity or irrelevant predictors. Next, we applied Ridge regularization, 
which penalizes large coefficients to stabilize the model, though it doesn't eliminate predictors, making it 
less interpretable than Lasso. Finally, we used Lasso regularization, which not only penalizes coefficients but also performs feature selection by shrinking some to zero, improving interpretability. Comparing their 
predictive power helps determine which approach balances accuracy and simplicity best.


#### Support Vector Machine

Can handle linear and non-linear decision boundaries. Using a linear kernel is good for approximately linear relationships (which it seems like our data is). Does not assume any specific distribution of predictors (which is good because none of our predictors are normal) 



#### Random Forest

Does not assume linear or nonlinear relationship between predictors and response. Good for non-normal variables.

#### Assessment

Compare the results of Logistic Regression, SVM, and Random Forest

# Results

# References

Davide Chicco, Giuseppe Jurman: Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone. BMC Medical Informatics and Decision Making 20, 16 (2020). https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-020-1023-5 
