---
title: "Slideshow-Kelsey"
subtitle: "DSCI 445"
author: "Group 8: Kelsey Britton, James Chinnery, Robin Thrush, Kaitlynn Walston"
output: 
  ioslides_presentation:
    css: styles.css
---

```{r setup, include=FALSE}
set.seed(445)
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(tidymodels)
library(knitr)
library(kableExtra)
clean_data <- read_csv("clean_movie_data.csv")
source("linreg.R")
```

```{r, include=F}
rf <- readRDS("final_rf_results.rds")
rf_plot_data <- collect_predictions(rf) %>%
  mutate(
    pred_dollars = exp(.pred),
    truth_dollars = exp(gross)
  )
binnedrf <- readRDS("binned_rf_results.rds")
binned_plot_data <- collect_predictions(binnedrf) %>%
  mutate(
    pred_dollars = exp(.pred),
    truth_dollars = exp(gross)
  )
combined_plot_data <- bind_rows(
  rf_plot_data %>% mutate(Model = "Target Encoding"),
  binned_plot_data %>% mutate(Model = "Binary Threshold Encoding")
)
r2_target <- collect_metrics(rf) %>% 
  filter(.metric == "rsq") %>% 
  pull(.estimate) %>% 
  round(3)

r2_binary <- collect_metrics(binnedrf) %>% 
  filter(.metric == "rsq") %>% 
  pull(.estimate) %>% 
  round(3)
```

## Tree Based Models

```{r compare-plot, echo=FALSE, fig.width=9, fig.height=4.5, out.width="100%"}
plot_labels <- tibble(
  Model = c("Target Encoding", "Binary Threshold Encoding"),  
  label = c(paste0("R2: ", r2_target), paste0("R2: ", r2_binary)),               
  x     = c(1e8, 1e8),                             
  y     = c(1e4, 1e4)                              
)

ggplot(combined_plot_data, aes(x = truth_dollars, y = pred_dollars)) +
  
  geom_point(alpha = 0.3, size = 1.5, color = "#2c3e50") +
  
  geom_abline(lty = 2, color = "#e74c3c", linewidth = 1) +
  
  facet_wrap(~Model) + 
  
  geom_text(
    data = plot_labels,             
    aes(x = x, y = y, label = label), 
    inherit.aes = FALSE,           
    size = 5
  ) +
  
  scale_x_log10(labels = label_dollar(scale_cut = cut_short_scale())) +
  scale_y_log10(labels = label_dollar(scale_cut = cut_short_scale())) +
  
  # Labels
  labs(
    x = "Actual Revenue",
    y = "Predicted Revenue",
    title = "Predicted vs Actual Gross Revenue with Random Forest",
  ) +
  theme_minimal(base_size = 14) +
  theme(panel.spacing = unit(2, "lines")) # Add space between plots
```

## Random Forest Performance {.columns-2}
<br>

```{r calc-metrics, echo=FALSE, fig.width=6, out.width="100%"}
mape_val <- binned_plot_data %>%
  summarise(
    # Formula: Median( Abs( (Actual - Pred) / Actual ) )
    score = median( abs((truth_dollars - pred_dollars) / truth_dollars) )
  ) %>%
  pull(score)

perf_metrics <- tibble(
  Metric = c("R-Squared", "RMSE (Dollars)", "MAE (Dollars)", "MdAPE (Avg % Error)"),
  Value = c(
    r2_binary, 
    scales::dollar(rmse(binned_plot_data, truth = truth_dollars, estimate = pred_dollars)$.estimate),
    scales::dollar(mae(binned_plot_data, truth = truth_dollars, estimate = pred_dollars)$.estimate),
    scales::percent(mape_val, accuracy = 1) # <--- New Line
  )
)


# 2. Calculate RMSE vs Gross Revenue (Plot)
# We split movies into 10 "Revenue Tiers" (Deciles) to see how error changes
rmse_by_gross <- binned_plot_data %>%
  mutate(gross_bin = ntile(truth_dollars, 10)) %>%
  group_by(gross_bin) %>%
  summarise(
    avg_gross = mean(truth_dollars),
    bin_rmse  = rmse_vec(truth = truth_dollars, estimate = pred_dollars)
  )

perf_metrics %>%
  kbl() %>%
  kable_styling(font_size = 20, bootstrap_options = "striped")
```
<br>

* Poor model relative to the median gross revenue ~14m

* Has some utility predicting high vs low performers



```{r plots, echo=FALSE, out.width="100%", fig.height= 8}

ggplot(rmse_by_gross, aes(x = avg_gross, y = bin_rmse)) +
  geom_line(color = "#2c3e50", linewidth = 1) +
  geom_point(color = "#e74c3c", size = 3) +
  
  scale_x_log10(labels = label_dollar(scale_cut = cut_short_scale())) +
  scale_y_log10(labels = label_dollar(scale_cut = cut_short_scale())) +
  
  labs(
    title = "RMSE vs. Revenue",
    x = "Avg Gross Revenue",
    y = "RMSE (Error)"
  ) +
  theme_minimal(base_size = 14)
```

## Data Limitations 

You are absolutely right to ask for this‚Äîit is the specific visual your group requested ("Visuals: Predicted vs Actual"), and it is currently missing from your deck.

Just to clarify terms:

Predicted vs. Actual: Points go along a diagonal line (What your group asked for).

Fitted vs. Residuals: Points fan out like a megaphone (The "Error Analysis").

Since your group explicitly asked for the Predicted vs. Actual, here is the code to generate that specific slide.

üéûÔ∏è Slide 3: Predicted vs. Actual
Copy this block to create your third slide.

Markdown

## Predicted vs. Actual Revenue

```{r resid-plot, echo=FALSE, fig.width=10, fig.height=4.5, out.width="100%"}
# 1. Calculate Residuals
resid_data <- binned_plot_data %>%
  mutate(residual = truth_dollars - pred_dollars)

# 2. Plot
ggplot(resid_data, aes(x = pred_dollars, y = residual)) +
  
  # The Zero Line (Perfect Prediction)
  geom_hline(yintercept = 0, color = "#e74c3c", linewidth = 1.5, linetype = "dashed") +
  
  # The Residual Points
  geom_point(alpha = 0.4, size = 2.5, color = "#2c3e50") +
  
  # Scales
  # X is Log Scale because Revenue varies wildly
  scale_x_log10(labels = label_dollar(scale_cut = cut_short_scale())) +
  # Y cannot be log-scaled (because errors can be negative), so we use standard dollars
  scale_y_continuous(labels = label_dollar(scale_cut = cut_short_scale())) +
  
  labs(
    title = "Residuals vs. Fitted Values",
    x = "Predicted Revenue (Fitted)",
    y = "Residual Error (Actual - Predicted)"
  ) +
  theme_minimal(base_size = 18)

```

* Homoscedasticity is not an assumption in this model
* Illustrates gaps in the data for the highest performing titles 