---
title: "Tree_Forest"
output: html_document
---

```{r}
set.seed(567)
library(tidyverse)
library(embed)
library(kerasnip)
library(tidymodels)
library(ranger)
library(xgboost)
library(doParallel)
```
```{r multicore stuff to hopefully run faster}
# Check total available cores on your machine
all_cores <- parallel::detectCores(logical = FALSE) 

# Recommended: Leave 2 cores free for the operating system and RStudio itself
# This prevents RAM over-allocation and system crashes.
safe_cores <- all_cores - 2

# Create the cluster (if safe_cores > 0)
if (safe_cores > 0) {
    cl <- makePSOCKcluster(safe_cores) 
    registerDoParallel(cl)
    cat(paste("Running on", safe_cores, "cores."))
} else {
    cat("Running sequentially (single core).")
}
```


```{r cleaning}
movies_fresh <- read.csv("Movie_Industry_1554_84.csv")

#fills and flags zero/na budgets 
movies_fresh <- movies_fresh |> 
  mutate(date_obj = parse_date_time(released, orders = c("ymd", "mdy", "dmy", "my" ,"ym", "y"))) %>% # defaults unknown months to jan
  mutate(
    year = year(date_obj), 
    release_month = month(date_obj, label = TRUE, abbr = FALSE)  %>% as.factor()
  ) %>%
  select(-date_obj, -released) %>% 
        mutate(budget = ifelse(budget == 0, NA, budget),
               budget_missing = ifelse(is.na(budget),1,0)) |>
        group_by(year) |>
        mutate(budget = ifelse(is.na(budget) | budget == 0,
                               median(budget, na.rm = TRUE),
                               budget)) |>
              ungroup() %>% 
  mutate(across(
    c(company, country, director, name, star, writer),
    ~ .x %>% 
        str_replace_all("[^a-zA-Z0-9 ]", " ") %>% 
        str_squish())) %>%
  mutate(gross = log(gross)) %>%
  mutate(budget = log(budget))
sum(is.na(movies_fresh))

```

```{r data prep}
#Strata forces the distritbution of gross to be equal across train/test
data_split <- initial_split(movies_fresh, prop = 0.75, strata = gross)
train_data <- training(data_split)
test_data  <- testing(data_split)
folds <- vfold_cv(train_data, v = 5)

high_card_cols <- c("director", "company", "writer", "star", "country")

movie_rec <- recipe(gross ~ ., data = train_data) %>%
  update_role(name, new_role = "id") %>%
  step_string2factor(all_nominal_predictors()) %>%
  step_unknown(release_month, genre, rating) %>%
  step_novel(release_month, genre, rating) %>% # makes the code not break when something new is in test
  step_unorder(release_month) %>%
  step_mutate(rating = fct_collapse(rating, NR = c("UNRATED", "Not specified", "NOT RATED", 
         "TV-PG", "TV-MA", "TV-14", "B", "B15"))) %>% # Drops junk and weird categories 
  #low cardinally nominal predictors
  step_dummy(release_month, genre, rating,) %>% 
  #high cardinality nominals
  step_lencode_mixed(director, company, writer, star, country, 
    outcome = vars(gross)) %>% 
  step_rm(X)

prepped_recipe <- prep(movie_rec, training = train_data)
processed_data <- bake(prepped_recipe, new_data = NULL)
```

```{r model specs}
forest_spec <- rand_forest(
  trees = 100,
  mtry = tune(),
  min_n =  tune()) %>%
  set_engine("ranger") %>% 
  set_mode("regression")


boost_spec <- boost_tree(
  learn_rate = tune(),
  tree_depth = tune(),
  min_n = tune(),
  trees = 100) %>%
  set_engine('xgboost') %>%
  set_mode("regression")


```

```{r workflows}
forest_workflow <- workflow() %>% 
  add_recipe(movie_rec) %>% 
  add_model(forest_spec)

boost_workflow <- workflow() %>% 
  add_recipe(movie_rec) %>% 
  add_model(boost_spec)
```

```{r tuning}
forest_params <- extract_parameter_set_dials(forest_workflow) %>%
  update(mtry = mtry(range = c(1, 45)))

forest_inital_results <- tune_grid(
  forest_workflow,
  resamples = folds,
  grid = 5,
  control = control_grid(save_pred = TRUE)
)

forest_results <- tune_bayes(
  forest_workflow, 
  resamples = folds,
  iter = 20,
  initial = forest_inital_results,
  param_info = forest_params,
  control = control_bayes(no_improve = 10, save_pred = T)
)


boost_initial_grid <- grid_latin_hypercube( # just a cube technically 
  tree_depth(),
  min_n(), 
  learn_rate(),
  size = 5)

boost_initial_results <- tune_grid(
  boost_workflow,
  resamples = folds,
  grid = boost_initial_grid,
  control = control_grid(save_pred = TRUE)
)

boost_result <- tune_bayes(
  boost_workflow, 
  resamples = folds,
  iter = 20,
  initial = boost_initial_results,
  control = control_bayes(no_improve = 10, save_pred = T)
)
```



```{r results code for not log transformed}
autoplot(forest_results)
autoplot(boost_result)
```

```{r results}
best_config <- show_best(boost_result, metric = "rmse", n = 1) %>% 
  select(.config)

full_metrics_boost <- collect_metrics(boost_result)
final_winner_metrics_boost <- full_metrics_boost %>%
  filter(.config == best_config$.config)

full_metrics_forest <- collect_metrics(forest_results)
final_winner_metrics_forest <- full_metrics_forest %>%
  filter(.config == best_config$.config)

print(final_winner_metrics_forest)
print(final_winner_metrics_boost)
```

```{r final fit}
best_params_rf <- select_best(forest_results, metric = "rmse")
final_forest_workflow <- forest_workflow %>%
  finalize_workflow(best_params_rf) %>% 
  
  # OVERRIDE: Set the final tree count to 1000 for maximum accuracy
  update_model(
    rand_forest(trees = 1000) %>% 
      set_engine("ranger") %>% 
      set_mode("regression")
  )

final_fit_results <- last_fit(final_forest_workflow, split = data_split)
```

```{r}
final_test_metrics <- collect_metrics(final_fit_results)
print("Final Test Set Metrics:")
print(final_test_metrics)
```

```{r}
# 1. Create the Dollar Dataframe (Convert Log -> Dollars)
final_predictions_dollars <- collect_predictions(final_fit_results) %>%
  mutate(
    pred_dollars = exp(.pred), 
    gross_dollars = exp(gross) 
  ) %>%
  # Join with test data to get the 'score' back for plotting
  bind_cols(testing(data_split) %>% select(score))

# 2. Calculate TRUE Dollar RMSE (for the subtitle)
dollar_rmse <- final_predictions_dollars %>%
  metrics(truth = gross_dollars, estimate = pred_dollars) %>%
  filter(.metric == "rmse") %>%
  pull(.estimate)

# 3. Generate the Plot with Coloring
predicted_vs_actual_plot <- final_predictions_dollars %>%
  ggplot(aes(x = gross_dollars, y = pred_dollars, color = score)) + # <--- ADDED COLOR HERE
    
    # Points
    geom_point(alpha = 0.6, size = 2, color = "blue") +
    
    # Perfect fit line
    geom_abline(lty = 2, color = "red", size = 1.2) +

    
    # Log Scales for Axes (Keeps dollars readable)
    scale_x_log10(labels = label_dollar(scale_cut = cut_short_scale())) +
    scale_y_log10(labels = label_dollar(scale_cut = cut_short_scale())) +
    
    # Aesthetics
    labs(
        title = "Random Forest: Predicted vs. Actual Revenue",
        subtitle = paste0("R-Squared: ", round(final_test_metrics$.estimate[final_test_metrics$.metric == "rsq"], 3), 
                          " | True Dollar RMSE: ", scales::dollar(dollar_rmse)),
        x = "Actual Gross Revenue",
        y = "Predicted Gross Revenue"
    ) +
    coord_fixed() + 
    theme_minimal()

print(predicted_vs_actual_plot)
```

```{r}
raw_gross <- movies_fresh %>% 
  select(gross) %>%
  mutate(gross = exp(gross))
summary(raw_gross)
```
```{r}
linear <- lm(gross ~budget, data = processed_data)
summary(linear)
```

```{r}
# 2. Calculate MAE
mae_metric <- final_predictions_dollars %>%
  metrics(truth = gross_dollars, estimate = pred_dollars) %>%
  filter(.metric == "mae") %>%
  pull(.estimate)

print(paste("Final Test MAE:", scales::dollar(mae_metric)))

```
```{r}
library(tidyverse)
library(scales)

# 1. Prepare Data: Join predictions with the original 'budget' column
plot_data_binned <- final_predictions_dollars %>%
  bind_cols(testing(data_split) %>% select(budget)) %>% # Bring back budget
  mutate(
    # Create 10 Bins (Deciles) based on Budget
    # This groups the cheapest 10% together, the next 10%, etc.
    budget_bin = ntile(budget, 10) 
  ) %>%
  # Calculate RMSE for EACH bin separately
  group_by(budget_bin) %>%
  summarise(
    bin_rmse = rmse_vec(truth = gross_dollars, estimate = pred_dollars),
    avg_budget = mean(budget), # To plot on X-axis
    n_movies = n() # Just to verify we have enough data per bin
  )

# 2. Plot RMSE trend
ggplot(plot_data_binned, aes(x = avg_budget, y = bin_rmse)) +
  
  # The Line Trend
  geom_line(color = "#2c3e50", size = 1) +
  geom_point(color = "#e74c3c", size = 3) +
  
  # Scales
  scale_x_log10(labels = label_dollar(scale_cut = cut_short_scale())) +
  scale_y_continuous(labels = label_dollar(scale_cut = cut_short_scale())) +
  
  # Labels
  labs(
    title = "Does Money Bring Problems?",
    subtitle = "RMSE (Error Variance) increases as Budget increases",
    x = "Average Budget (Log Scale)",
    y = "RMSE (Model Error)"
  ) +
  theme_minimal()

```



